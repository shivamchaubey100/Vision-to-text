# Vision-to-Text

## Week 1

- Install and setup [Python](https://docs.python.org/3/tutorial/index.html), [NumPy](https://numpy.org/doc/1.26/user/absolute_beginners.html), [Pandas](https://pandas.pydata.org/docs/getting_started/index.html#getting-started), [Matplotlib](https://matplotlib.org/stable/index.html) and read their documentation for reference.

- ### Resources :
    - Python - https://www.w3schools.com/python/ : For starters you can read till functions
    - Numpy - https://www.w3schools.com/python/numpy/ : For starters you can read till Array iteration
    - Pandas -  https://www.geeksforgeeks.org/pandas-tutorial/
    - Matplotlib - https://www.w3schools.com/python/matplotlib_intro.asp : Just go over it no need to remember everything

- ### Video Tutorials :
    - Numpy - https://www.youtube.com/watch?v=QUT1VHiLmmI
    - Pandas - https://www.youtube.com/playlist?list=PL-osiE80TeTsWmV9i9c58mdDCSskIFdDS

- You can also check W3Schools for all these libraries as it provides guided and normal paced tutorials

- For those interested can read up on Object Oriented Programming([OOPs](https://www.javatpoint.com/python-oops-concepts)) in python

- [Assignment link](Assignment1.ipynb)

- Also if you want to master pandas and numpy, the following resources can be referred:
  - [Numpy 100 puzzles](https://github.com/rougier/numpy-100)
  - [Pandas 100 puzzles](https://github.com/ajcr/100-pandas-puzzles) (Recommended)
 
## Week 2

### Resources :
- Linear Regression :
    - [PDF_1](intro_regression.pdf)
    - [PDF_2](linear_regression.pdf)
- Logistic Regression :
    - [PDF_1](logistic_regression.pdf)
- Bias and Variance :
    - [PDF_1](bias_variance.pdf)

These are my course slides and are a little more maths centric so if you want you can just read them once.

### Video Lectures :
- [Gradient Descent](https://www.youtube.com/watch?v=sDv4f4s2SB8)
- [Stochastic Gradient Descent](https://www.youtube.com/watch?v=vMh0zPT0tLI)
- [Linear Regression](https://www.youtube.com/watch?v=7ArmBVF2dCs)
- [Logictic Regression](https://www.youtube.com/watch?v=yIYKR4sgzI8)

You can check out these videos it will give you some good visualization and intuition.

## Week 3
The main ojective of this week is to learn about basic Artificial Neural Networks and the fundamentals of optimisers. We'll be using either pytorch, keras or tensorflow for the implementaion of neural nets.
Don't spend too much time on pytorch syntax.
### Resources:
- Basics of Neural Networks:
    - [3Blue1Brown - Neural Networks](https://www.youtube.com/watch?v=aircAruvnKk)
    - [Youtube Playlist for Neural Network](https://www.youtube.com/watch?v=mlk0rddP3L4&list=PLuhqtP7jdD8CftMk831qdE8BlIteSaNzD&pp=iAQB)
- PyTorch:
    - [PyTorch Official Documentation](https://pytorch.org/docs/stable/index.html)
    - either [this](https://www.youtube.com/watch?v=U0i7-c3Vrgc&list=PLZoTAELRMXVNxYFq_9MuiUdn2YnlFqmMK)
    - or [this](https://www.youtube.com/watch?v=V_xro1bcAuA&t=2598s&pp=ygUQcHl0b3JjaCB0dXRvcmlhbA%3D%3D)
    - [Getting Started with PyTorch](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html)
    - [PyTorch Cheat Sheet](https://pytorch.org/tutorials/beginner/ptcheat.html)
- Neural Networks with PyTorch:
    - [Neural Networks with PyTorch](https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html)
    - [Building Neural Networks in PyTorch](https://towardsdatascience.com/building-neural-networks-with-pytorch-759ebca336ed)
- Optimization Techniques:
    - [Optimization in Machine Learning](https://medium.com/@koushikkushal95/optimization-algorithms-in-machine-learning-a-comprehensive-guide-to-understand-the-concept-and-3db1df7a2f59)
    - [PyTorch Optimizers](https://pytorch.org/docs/stable/optim.html)
      
- Neural Network from Scratch (Optional)(Only if time permits)
    - [Neural Network from Scratch by Andrej Karpathy](https://youtu.be/VMj-3S1tku0?si=4C8yBmo67kQqsoA6)
  

In case someone prefers keras or tensorflow.
You don't have to learn all three frameworks, just go for any one of these.

- Keras:
    - [Keras Official Documentation](https://keras.io/)
    - [Getting Started with Keras](https://keras.io/getting_started/)
    - [Keras Cheat Sheet](https://www.geeksforgeeks.org/keras-cheatsheet/)
- TensorFlow:
    - [TensorFlow Official Documentation](https://www.tensorflow.org/learn)
    - [Getting Started with TensorFlow](https://www.tensorflow.org/tutorials)
    - [TensorFlow Cheat Sheet](https://www.tutorialspoint.com/tensorflow/tensorflow_quick_guide.htm)

 ## Week 4


The main objective of this week is to learn about Convolutional Neural Networks (CNNs), explore their architectures, and understand different CNN models. We'll be using frameworks like NumPy, PyTorch, TensorFlow, and Keras.



### Recap on Neural Networks
**Refer to the links below for a quick recap**:
- [What is a neural network?](https://www.youtube.com/watch?v=aircAruvnKk&ab_channel=3Blue1Brown)
- [Gradient descent: How neural networks learn](https://www.youtube.com/watch?v=IHZwWFHWa-w&ab_channel=3Blue1Brown)
- [What is backpropagation really doing?](https://www.youtube.com/watch?v=Ilg3gGewQ5U&ab_channel=3Blue1Brown)

For more in-depth knowledge, you can look for similar videos on YouTube. Here is a playlist on [Neural Networks by 3Blue1Brown](https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi).

### Basics of CNNs
1. **Introduction to CNNs**:
   - [What is a Convolutional Neural Network?](https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53)
   - [What is Convolution?](https://www.youtube.com/watch?v=KuXjwB4LzSA&ab_channel=3Blue1Brown)
   - [CS231n Convolutional Neural Networks for Visual Recognition](https://cs231n.github.io/)

### CNN Architectures
2. **Explore these Popular CNN Architectures**:
   - [VGGNet](https://arxiv.org/abs/1409.1556)
   - [GoogLeNet/Inception](https://arxiv.org/abs/1409.4842)
   - [ResNet](https://arxiv.org/abs/1512.03385)

### Implementation
For this week's assignment, we will be using NumPy, PyTorch, and TensorFlow. It is advised that you are comfortable with these libraries beforehand.

### Video Lectures
6. **Video Tutorials**:
   - [Deep Learning Specialization by Andrew Ng - Convolutional Neural Networks](https://www.coursera.org/learn/convolutional-neural-networks)
   - [Stanford CS231n - Convolutional Neural Networks](https://www.youtube.com/watch?v=iaSUYvmCekI)
   - [Simplilearn - Convolutional Neural Network (CNN) Tutorial](https://www.youtube.com/watch?v=YRhxdVk_sIs)
   - [Sentdex - CNNs with Keras](https://www.youtube.com/watch?v=WvoLTXIjBYU)

### Optional Deep Dive
7. **Advanced Topics (Optional)**:
   - [Transfer Learning with CNNs](https://towardsdatascience.com/transfer-learning-with-tf-2-0-ff960901046d)
   - [Understanding and Visualizing CNNs](https://www.analyticsvidhya.com/blog/2021/05/convolutional-neural-networks-cnn/)
   - [Kaggle - Transfer Learning and CNN Architectures](https://www.kaggle.com/code/dansbecker/transfer-learning)

## Week 5

This week, we'll delve into the fascinating world of Recurrent Neural Networks (RNNs) and explore how they can be used to process sequences of data, such as sentences and text.

## Coursera Course

### **Strongly Recommended**

**Complete the first two weeks of the course ["Sequence Models" by Andrew Ng](https://www.coursera.org/learn/nlp-sequence-models?) on Coursera.**

This course covers essential concepts related to sequential neural networks and word embeddings. You can audit the content for free, providing a solid theoretical foundation for the topics we'll cover this week.

## Understanding RNNs

Recurrent Neural Networks (RNNs) are designed to process sequences of data. Learn the basics of RNNs and how they maintain a memory of past inputs:

- [**Understanding RNNs - Towards Data Science**](https://towardsdatascience.com/illustrated-guide-to-recurrent-neural-networks-79e5eb8049c9)
- [**Recurrent Neural Networks (RNN) - Deep Learning Basics**](https://www.youtube.com/watch?v=UNmqTiOnRfg)

We will also explore Natural Language Processing (NLP), a field that focuses on the interaction between computers and humans using natural language. Understanding the fundamentals of text processing, language modeling, and sentiment analysis will be crucial for tasks such as chatbots, language translation, and text summarization.

## NLP (Natural Language Processing)
*CONTENTS*

- Word Embeddings
- Text Preprocessing
- Sentiment Analysis

### Word Embeddings

Neural networks cannot process words directly; they deal only with numerical vectors and their computations. To feed text as input to a neural network, we need to convert it into vector form using word embeddings. Various techniques (TF-IDF, Skip-gram, CBOW) and implementations (Glove, FastText, etc.) exist for this purpose.

Read these articles:

- [*Brief conceptual overview*](https://www.geeksforgeeks.org/word-embeddings-in-nlp/) (Must read)
- [*TF-IDF*](https://www.geeksforgeeks.org/understanding-tf-idf-term-frequency-inverse-document-frequency/)
- [*CBOW*](https://www.geeksforgeeks.org/continuous-bag-of-words-cbow-in-nlp/)
- [*Skipgram*](https://www.geeksforgeeks.org/implement-your-own-word2vecskip-gram-model-in-python/)

### Text Preprocessing

Text preprocessing in NLP is essential to clean and transform raw text data, addressing issues like irrelevant characters, formatting, and inconsistencies to ensure its suitability for analysis by machine learning models.

*Main Topics to Keep in Mind:*

- Tokenization
- Lowercase conversion
- Stopwords removal
- Stemming
- Lemmatization

*RESOURCES*

- [*Detailed guide*](https://www.analyticsvidhya.com/blog/2021/06/text-preprocessing-in-nlp-with-python-codes/) (Recommended)
- [*Youtube Video*](https://www.youtube.com/watch?v=nxhCyeRR75Q), focusing more on post-cleanup steps like tokenization, stemming, and lemmatization

### Sentiment Analysis

Sentiment analysis in NLP involves determining the emotional tone or subjective information expressed in a piece of text, helping identify and quantify sentiments such as positive, negative, or neutral attitudes.

- [Short intro](https://www.geeksforgeeks.org/what-is-sentiment-analysis/)

### NLTK vs spaCy

NLTK is versatile and suitable for learning and experimenting with various NLP concepts, making it popular in academic and research settings. spaCy, with its emphasis on speed and ease of use, is favored in the industry for developing efficient and scalable NLP applications. The choice between NLTK and spaCy depends on the specific needs of a project and the user's goals, whether it be educational exploration or real-world application development.

### TEXT PROCESSING WITH SPACY

*RESOURCES*

- [*Spacy Documentation*](https://spacy.io/usage/spacy-101)
- [*Spacy Video Tutorial*](https://youtu.be/THduWAnG97k)

*Main Topics to Keep in Mind:*

- Tokenization
- Parts of Speech Tagging
- Named Entity Recognition
